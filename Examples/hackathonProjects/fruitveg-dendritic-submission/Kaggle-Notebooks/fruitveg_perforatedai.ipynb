{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3173719,"sourceType":"datasetVersion","datasetId":952827}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames[:1]:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-14T21:28:23.993136Z","iopub.execute_input":"2026-01-14T21:28:23.993753Z","iopub.status.idle":"2026-01-14T21:28:33.967547Z","shell.execute_reply.started":"2026-01-14T21:28:23.993722Z","shell.execute_reply":"2026-01-14T21:28:33.966837Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/fruit-and-vegetable-image-recognition/validation/capsicum/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/sweetcorn/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/orange/Image_1.png\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/tomato/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/turnip/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/ginger/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/raddish/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/pomegranate/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/pineapple/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/jalepeno/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/apple/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/carrot/Image_2.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/lettuce/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/bell pepper/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/eggplant/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/beetroot/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/kiwi/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/pear/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/cabbage/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/cauliflower/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/paprika/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/lemon/Image_1.png\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/sweetpotato/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/grapes/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/cucumber/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/corn/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/banana/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/garlic/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/chilli pepper/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/watermelon/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/mango/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/peas/Image_6.png\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/onion/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/potato/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/spinach/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/validation/soy beans/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/capsicum/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/sweetcorn/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/orange/Image_1.png\n/kaggle/input/fruit-and-vegetable-image-recognition/test/tomato/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/turnip/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/ginger/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/raddish/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/pomegranate/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/pineapple/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/jalepeno/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/apple/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/carrot/Image_2.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/lettuce/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/bell pepper/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/eggplant/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/beetroot/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/kiwi/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/pear/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/cabbage/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/cauliflower/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/paprika/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/lemon/Image_1.png\n/kaggle/input/fruit-and-vegetable-image-recognition/test/sweetpotato/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/grapes/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/cucumber/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/corn/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/banana/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/garlic/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/chilli pepper/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/watermelon/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/mango/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/peas/Image_6.png\n/kaggle/input/fruit-and-vegetable-image-recognition/test/onion/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/potato/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/spinach/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/test/soy beans/Image_4.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/capsicum/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/sweetcorn/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/orange/Image_1.png\n/kaggle/input/fruit-and-vegetable-image-recognition/train/tomato/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/turnip/Image_53.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/ginger/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/raddish/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/pomegranate/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/pineapple/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/jalepeno/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/apple/Image_69.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/carrot/Image_53.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/lettuce/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/bell pepper/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/eggplant/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/beetroot/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/kiwi/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/pear/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/cabbage/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/cauliflower/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/paprika/Image_68.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/lemon/Image_1.png\n/kaggle/input/fruit-and-vegetable-image-recognition/train/sweetpotato/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/grapes/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/cucumber/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/corn/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/banana/Image_69.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/garlic/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/chilli pepper/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/watermelon/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/mango/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/peas/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/onion/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/potato/Image_53.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/spinach/Image_22.jpg\n/kaggle/input/fruit-and-vegetable-image-recognition/train/soy beans/Image_22.jpg\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip -q install git+https://github.com/PerforatedAI/PerforatedAI.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T21:28:42.514687Z","iopub.execute_input":"2026-01-14T21:28:42.515352Z","iopub.status.idle":"2026-01-14T21:28:55.102784Z","shell.execute_reply.started":"2026-01-14T21:28:42.515321Z","shell.execute_reply":"2026-01-14T21:28:55.101990Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for perforatedai (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from __future__ import print_function\n\nimport argparse\nimport json\nimport os\nimport random\nimport time\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\nfrom torchvision import datasets, transforms\nfrom torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\n\n# PerforatedAI \nfrom perforatedai import globals_perforatedai as GPA\nfrom perforatedai import utils_perforatedai as UPA\n\n\n# ────────────────────────────────────────────────────────────────\n# Utils\n# ────────────────────────────────────────────────────────────────\ndef set_seed(seed: int):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\n\ndef ensure_dir(path: str):\n    if path and not os.path.exists(path):\n        os.makedirs(path, exist_ok=True)\n\n\ndef count_params(model: nn.Module) -> int:\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n\n# ────────────────────────────────────────────────────────────────\n# Model\n# ────────────────────────────────────────────────────────────────\ndef build_model(num_classes: int):\n    weights = MobileNet_V3_Small_Weights.DEFAULT\n    model = mobilenet_v3_small(weights=weights)\n    in_f = model.classifier[-1].in_features\n    model.classifier[-1] = nn.Linear(in_f, num_classes)\n    return model, weights\n\n\n# ────────────────────────────────────────────────────────────────\n# PerforatedAI config GD dendrites only\n# ────────────────────────────────────────────────────────────────\ndef configure_perforatedai(args):\n    \"\"\"\n    Path A compliance:\n      - uses initialize_pai()\n      - uses add_validation_score()\n      - generates PAI/PAI.png\n    And critically:\n      - NO Perforated Backprop (PB), so no UPB/initialize_pb required.\n    \"\"\"\n\n    # Improvement threshold schedule\n    if args.improvement_threshold == 0:\n        thresh = [0.01, 0.001, 0.0001, 0]\n    elif args.improvement_threshold == 1:\n        thresh = [0.001, 0.0001, 0]\n    else:\n        thresh = [0]\n    GPA.pc.set_improvement_threshold(thresh)\n\n    GPA.pc.set_candidate_weight_initialization_multiplier(\n        args.candidate_weight_init_mult\n    )\n\n    # Forward function used inside dendrites\n    if args.pai_forward_function == \"sigmoid\":\n        pai_forward = torch.sigmoid\n    elif args.pai_forward_function == \"relu\":\n        pai_forward = torch.relu\n    elif args.pai_forward_function == \"tanh\":\n        pai_forward = torch.tanh\n    else:\n        pai_forward = torch.sigmoid\n    GPA.pc.set_pai_forward_function(pai_forward)\n\n    # PATH A (GD dendrites):\n    # IMPORTANT: keep PB OFF to avoid any UPB/initialize_pb dependency.\n    if args.dendrite_mode == 0:\n        GPA.pc.set_max_dendrites(0)\n    else:\n        GPA.pc.set_max_dendrites(int(args.max_dendrites))\n\n    GPA.pc.set_perforated_backpropagation(False)  \n\n    # Recommended defaults\n    GPA.pc.set_testing_dendrite_capacity(False)\n    GPA.pc.set_weight_decay_accepted(True)\n    GPA.pc.set_verbose(False)\n\n\n# ────────────────────────────────────────────────────────────────\n# Train / Eval (PerforatedAI-aware)\n# ────────────────────────────────────────────────────────────────\ndef train_one_epoch(args, model, device, train_loader, optimizer, epoch):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data = data.to(device, non_blocking=True)\n        target = target.to(device, non_blocking=True)\n\n        optimizer.zero_grad(set_to_none=True)\n        output = model(data)\n        loss = nn.functional.cross_entropy(output, target)\n        loss.backward()\n        optimizer.step()\n\n        bs = data.size(0)\n        running_loss += loss.item() * bs\n        pred = output.argmax(dim=1)\n        correct += pred.eq(target).sum().item()\n        total += bs\n\n        if batch_idx % args.log_interval == 0:\n            pct = 100.0 * batch_idx / max(1, len(train_loader))\n            acc = 100.0 * correct / max(1, total)\n            print(\n                f\"Train Epoch: {epoch} [{batch_idx*bs}/{len(train_loader.dataset)} ({pct:.0f}%)] \"\n                f\"Loss: {loss.item():.6f}  Acc: {acc:.2f}%\"\n            )\n            if args.dry_run:\n                break\n\n    train_loss = running_loss / max(1, total)\n    train_acc = 100.0 * correct / max(1, total)\n\n    # Feed PerforatedAI the train score\n    GPA.pai_tracker.add_extra_score(train_acc, \"train\")\n\n    model.to(device)\n    return train_loss, train_acc\n\n\n@torch.no_grad()\ndef evaluate_and_maybe_restructure(args, model, device, loader, optimizer, scheduler, split_name=\"validation\"):\n    model.eval()\n    loss_sum = 0.0\n    correct = 0\n    total = 0\n\n    for data, target in loader:\n        data = data.to(device, non_blocking=True)\n        target = target.to(device, non_blocking=True)\n\n        output = model(data)\n        loss = nn.functional.cross_entropy(output, target, reduction=\"sum\")\n        loss_sum += loss.item()\n\n        pred = output.argmax(dim=1)\n        correct += pred.eq(target).sum().item()\n        total += target.size(0)\n\n    avg_loss = loss_sum / max(1, total)\n    acc = 100.0 * correct / max(1, total)\n\n    print(\n        f\"\\n{split_name.capitalize()} set: Average loss: {avg_loss:.4f}, \"\n        f\"Accuracy: {correct}/{total} ({acc:.2f}%)\\n\"\n    )\n\n    #  PerforatedAI validation hook \n    model, restructured, training_complete = GPA.pai_tracker.add_validation_score(acc, model)\n    model.to(device)\n\n    # If model changed, reset optimizer/scheduler via tracker\n    if restructured and not training_complete:\n        optim_args = {\"params\": model.parameters(), \"lr\": args.lr, \"weight_decay\": args.weight_decay}\n        sched_args = {\"step_size\": 1, \"gamma\": args.gamma}\n        optimizer, scheduler = GPA.pai_tracker.setup_optimizer(model, optim_args, sched_args)\n        print(\"[INFO] Model restructured → optimizer/scheduler reset.\")\n\n    return avg_loss, acc, model, optimizer, scheduler, training_complete, restructured\n\n\n# ────────────────────────────────────────────────────────────────\n# Main\n# ────────────────────────────────────────────────────────────────\ndef main():\n    parser = argparse.ArgumentParser(\n        description=\"Fruit/Veg — PerforatedAI  (GD dendrites) on MobileNetV3-Small\"\n    )\n\n    # Kaggle dataset dirs \n    parser.add_argument(\"--train-dir\", type=str, default=\"/kaggle/input/fruit-and-vegetable-image-recognition/train\")\n    parser.add_argument(\"--val-dir\", type=str, default=\"/kaggle/input/fruit-and-vegetable-image-recognition/validation\")\n    parser.add_argument(\"--test-dir\", type=str, default=\"/kaggle/input/fruit-and-vegetable-image-recognition/test\")\n\n    # Training hyperparams\n    parser.add_argument(\"--batch-size\", type=int, default=64)\n    parser.add_argument(\"--test-batch-size\", type=int, default=128)\n    parser.add_argument(\"--epochs\", type=int, default=200)  # PAI may stop early\n    parser.add_argument(\"--lr\", type=float, default=3e-4)\n    parser.add_argument(\"--gamma\", type=float, default=0.9)\n    parser.add_argument(\"--weight-decay\", type=float, default=1e-4)\n\n    # Runtime\n    parser.add_argument(\"--no-cuda\", action=\"store_true\", default=False)\n    parser.add_argument(\"--dry-run\", action=\"store_true\", default=False)\n    parser.add_argument(\"--seed\", type=int, default=42)\n    parser.add_argument(\"--log-interval\", type=int, default=20)\n    parser.add_argument(\"--num-workers\", type=int, default=2)\n\n    # Outputs\n    parser.add_argument(\"--save-model\", action=\"store_true\", default=True)\n    parser.add_argument(\"--out-dir\", type=str, default=\"./outputs\")\n    parser.add_argument(\"--model-name\", type=str, default=\"fruitveg_mnv3s_pathA_gd_dendritic.pt\")\n    parser.add_argument(\"--metrics-name\", type=str, default=\"pathA_gd_dendritic_metrics.json\")\n    parser.add_argument(\"--save-name\", type=str, default=\"PAI\")  # this yields ./PAI/PAI.png\n\n    # PerforatedAI knobs (Path A)\n    parser.add_argument(\"--dendrite-mode\", type=int, default=1, choices=[0, 1])  # 0=control, 1=GD dendrites\n    parser.add_argument(\"--max-dendrites\", type=int, default=5)\n    parser.add_argument(\"--improvement-threshold\", type=int, default=1, choices=[0, 1, 2])\n    parser.add_argument(\"--candidate-weight-init-mult\", type=float, default=0.01)\n    parser.add_argument(\"--pai-forward-function\", type=str, default=\"sigmoid\", choices=[\"sigmoid\", \"relu\", \"tanh\"])\n\n    args = parser.parse_args()\n\n    # Validate dirs\n    for p in [args.train_dir, args.val_dir, args.test_dir]:\n        if not os.path.isdir(p):\n            raise FileNotFoundError(f\"Directory not found: {p}\")\n\n    use_cuda = (not args.no_cuda) and torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n    print(\"[INFO] device:\", device)\n\n    set_seed(args.seed)\n    ensure_dir(args.out_dir)\n\n    # Transforms: keep aligned to your baseline for fair comparison\n    _, weights = build_model(num_classes=2)\n\n    IMAGENET_MEAN = (0.485, 0.456, 0.406)\n    IMAGENET_STD = (0.229, 0.224, 0.225)\n\n    train_transform = transforms.Compose(\n        [\n            transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.10),\n            transforms.ToTensor(),\n            transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n        ]\n    )\n    eval_transform = weights.transforms()\n\n    train_ds = datasets.ImageFolder(args.train_dir, transform=train_transform)\n    val_ds = datasets.ImageFolder(args.val_dir, transform=eval_transform)\n    test_ds = datasets.ImageFolder(args.test_dir, transform=eval_transform)\n\n    # Ensure mapping consistency across splits\n    if val_ds.class_to_idx != train_ds.class_to_idx:\n        raise ValueError(\n            \"Class mapping mismatch train vs val.\\n\"\n            f\"train: {train_ds.class_to_idx}\\nval: {val_ds.class_to_idx}\"\n        )\n    if test_ds.class_to_idx != train_ds.class_to_idx:\n        raise ValueError(\n            \"Class mapping mismatch train vs test.\\n\"\n            f\"train: {train_ds.class_to_idx}\\ntest: {test_ds.class_to_idx}\"\n        )\n\n    num_classes = len(train_ds.classes)\n    print(\"[INFO] num_classes:\", num_classes)\n    print(\"[INFO] example classes:\", train_ds.classes[:10], \"...\")\n\n    train_loader = torch.utils.data.DataLoader(\n        train_ds,\n        batch_size=args.batch_size,\n        shuffle=True,\n        num_workers=args.num_workers,\n        pin_memory=use_cuda,\n    )\n    val_loader = torch.utils.data.DataLoader(\n        val_ds,\n        batch_size=args.test_batch_size,\n        shuffle=False,\n        num_workers=args.num_workers,\n        pin_memory=use_cuda,\n    )\n    test_loader = torch.utils.data.DataLoader(\n        test_ds,\n        batch_size=args.test_batch_size,\n        shuffle=False,\n        num_workers=args.num_workers,\n        pin_memory=use_cuda,\n    )\n\n    # Build base model\n    model, _ = build_model(num_classes=num_classes)\n    model = model.to(device)\n\n    base_params = count_params(model)\n    print(f\"[INFO] base trainable params: {base_params:,} ({base_params/1e6:.2f}M)\")\n\n    # Configure PerforatedAI \n    configure_perforatedai(args)\n\n    \n\n    # Avoid interactive pdb stop in Kaggle\n    GPA.pc.set_unwrapped_modules_confirmed(True)\n    GPA.pc.set_verbose(False)\n\n\n    #Mandatory hook: initialize_pai wraps the model + creates graph artifacts\n    model = UPA.initialize_pai(model, save_name=args.save_name)\n    model.to(device)\n\n    # Setup optimizer / scheduler THROUGH PAI tracker (important)\n    GPA.pai_tracker.set_optimizer(optim.AdamW)\n    GPA.pai_tracker.set_scheduler(StepLR)\n\n    optim_args = {\"params\": model.parameters(), \"lr\": args.lr, \"weight_decay\": args.weight_decay}\n    sched_args = {\"step_size\": 1, \"gamma\": args.gamma}\n    optimizer, scheduler = GPA.pai_tracker.setup_optimizer(model, optim_args, sched_args)\n\n    best_val_acc = -1.0\n    best_state = None\n    history = []\n    start_time = time.time()\n\n    training_complete = False\n\n    for epoch in range(1, args.epochs + 1):\n        tr_loss, tr_acc = train_one_epoch(args, model, device, train_loader, optimizer, epoch)\n\n        val_loss, val_acc, model, optimizer, scheduler, training_complete, restructured = (\n            evaluate_and_maybe_restructure(args, model, device, val_loader, optimizer, scheduler, \"validation\")\n        )\n\n        scheduler.step()\n\n        num_dendrites = int(GPA.pai_tracker.member_vars.get(\"num_dendrites_added\", 0))\n        mode = str(GPA.pai_tracker.member_vars.get(\"mode\", \"\"))\n\n        history.append(\n            {\n                \"epoch\": epoch,\n                \"train_loss\": tr_loss,\n                \"train_acc\": tr_acc,\n                \"val_loss\": val_loss,\n                \"val_acc\": val_acc,\n                \"lr\": optimizer.param_groups[0][\"lr\"],\n                \"pai_num_dendrites_added\": num_dendrites,\n                \"pai_mode\": mode,\n                \"restructured\": bool(restructured),\n            }\n        )\n\n        print(f\"[INFO] PAI mode={mode} | dendrites_added={num_dendrites} | restructured={restructured}\")\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_state = {\n                \"model_state\": model.state_dict(),\n                \"classes\": train_ds.classes,\n                \"class_to_idx\": train_ds.class_to_idx,\n                \"best_val_acc\": best_val_acc,\n                \"base_params\": base_params,\n                \"args\": vars(args),\n            }\n            if args.save_model:\n                out_path = os.path.join(args.out_dir, args.model_name)\n                torch.save(best_state, out_path)\n                print(f\"[INFO] Saved best model to {out_path}\")\n\n        if args.dry_run:\n            break\n\n        if training_complete:\n            print(\"[INFO] PerforatedAI reports training complete. Stopping early.\")\n            break\n\n    # Load best checkpoint for final test\n    if best_state is not None and args.save_model:\n        ckpt_path = os.path.join(args.out_dir, args.model_name)\n        ckpt = torch.load(ckpt_path, map_location=device)\n        model.load_state_dict(ckpt[\"model_state\"])\n\n    # Final test evaluation (no restructuring)\n    model.eval()\n    test_loss_sum = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for data, target in test_loader:\n            data = data.to(device, non_blocking=True)\n            target = target.to(device, non_blocking=True)\n            output = model(data)\n            loss = nn.functional.cross_entropy(output, target, reduction=\"sum\")\n            test_loss_sum += loss.item()\n            pred = output.argmax(dim=1)\n            correct += pred.eq(target).sum().item()\n            total += target.size(0)\n\n    test_loss = test_loss_sum / max(1, total)\n    test_acc = 100.0 * correct / max(1, total)\n\n    print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{total} ({test_acc:.2f}%)\\n\")\n\n    elapsed = time.time() - start_time\n    num_dendrites_final = int(GPA.pai_tracker.member_vars.get(\"num_dendrites_added\", 0))\n    mode_final = str(GPA.pai_tracker.member_vars.get(\"mode\", \"\"))\n\n    metrics = {\n        \"best_val_acc\": best_val_acc,\n        \"final_test_acc\": test_acc,\n        \"final_test_loss\": test_loss,\n        \"base_params\": base_params,\n        \"elapsed_seconds\": elapsed,\n        \"pai_num_dendrites_added\": num_dendrites_final,\n        \"pai_mode\": mode_final,\n        \"history\": history,\n        \"required_graph_path\": f\"./{args.save_name}/{args.save_name}.png\",  # typically ./PAI/PAI.png\n    }\n\n    metrics_path = os.path.join(args.out_dir, args.metrics_name)\n    with open(metrics_path, \"w\") as f:\n        json.dump(metrics, f, indent=2)\n\n    print(f\"[DONE] Metrics saved to: {metrics_path}\")\n    print(f\"[DONE] Best Val Acc: {best_val_acc:.2f}% | Test Acc: {test_acc:.2f}%\")\n    print(f\"[DONE] Time: {elapsed/60:.1f} minutes\")\n\n    print(\"\\n[IMPORTANT] For judging, include the PerforatedAI graph image:\")\n    print(f\"  -> ./{args.save_name}/{args.save_name}.png  (usually ./PAI/PAI.png)\\n\")\n\n\nif __name__ == \"__main__\":\n    import sys\n    # Kaggle notebooks inject args like `-f ...json` → wipe them so argparse doesn't crash\n    sys.argv = [\"\"]\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T21:47:16.977206Z","iopub.execute_input":"2026-01-14T21:47:16.977825Z","iopub.status.idle":"2026-01-15T01:06:35.842398Z","shell.execute_reply.started":"2026-01-14T21:47:16.977798Z","shell.execute_reply":"2026-01-15T01:06:35.841566Z"}},"outputs":[{"name":"stdout","text":"[INFO] device: cuda\n[INFO] num_classes: 36\n[INFO] example classes: ['apple', 'banana', 'beetroot', 'bell pepper', 'cabbage', 'capsicum', 'carrot', 'cauliflower', 'chilli pepper', 'corn'] ...\n[INFO] base trainable params: 1,554,756 (1.55M)\nRunning Dendrite Experiment\nTrain Epoch: 1 [0/3115 (0%)] Loss: 3.693619  Acc: 1.56%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 1 [1280/3115 (41%)] Loss: 2.609549  Acc: 25.60%\nTrain Epoch: 1 [2560/3115 (82%)] Loss: 1.402737  Acc: 40.17%\n\nValidation set: Average loss: 0.8475, Accuracy: 262/351 (74.64%)\n\nAdding validation score 74.64387464\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 0, last improved epoch 0, total epochs 0, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\n[INFO] Saved best model to ./outputs/fruitveg_mnv3s_pathA_gd_dendritic.pt\nTrain Epoch: 2 [0/3115 (0%)] Loss: 0.886523  Acc: 79.69%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 2 [1280/3115 (41%)] Loss: 0.818896  Acc: 75.89%\nTrain Epoch: 2 [2560/3115 (82%)] Loss: 0.672635  Acc: 77.02%\n\nValidation set: Average loss: 0.4083, Accuracy: 301/351 (85.75%)\n\nAdding validation score 85.75498575\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 1, last improved epoch 1, total epochs 1, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\n[INFO] Saved best model to ./outputs/fruitveg_mnv3s_pathA_gd_dendritic.pt\nTrain Epoch: 3 [0/3115 (0%)] Loss: 0.431152  Acc: 87.50%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 3 [1280/3115 (41%)] Loss: 0.474521  Acc: 84.82%\nTrain Epoch: 3 [2560/3115 (82%)] Loss: 0.402274  Acc: 86.01%\n\nValidation set: Average loss: 0.2873, Accuracy: 315/351 (89.74%)\n\nAdding validation score 89.74358974\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 2, last improved epoch 2, total epochs 2, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\n[INFO] Saved best model to ./outputs/fruitveg_mnv3s_pathA_gd_dendritic.pt\nTrain Epoch: 4 [0/3115 (0%)] Loss: 0.421832  Acc: 85.94%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 4 [1280/3115 (41%)] Loss: 0.432418  Acc: 90.03%\nTrain Epoch: 4 [2560/3115 (82%)] Loss: 0.454606  Acc: 90.24%\n\nValidation set: Average loss: 0.2378, Accuracy: 323/351 (92.02%)\n\nAdding validation score 92.02279202\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 3, last improved epoch 3, total epochs 3, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\n[INFO] Saved best model to ./outputs/fruitveg_mnv3s_pathA_gd_dendritic.pt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 5 [0/3115 (0%)] Loss: 0.322145  Acc: 89.06%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 5 [1280/3115 (41%)] Loss: 0.263234  Acc: 92.93%\nTrain Epoch: 5 [2560/3115 (82%)] Loss: 0.317005  Acc: 92.19%\n\nValidation set: Average loss: 0.2102, Accuracy: 329/351 (93.73%)\n\nAdding validation score 93.73219373\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 4, last improved epoch 4, total epochs 4, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\n[INFO] Saved best model to ./outputs/fruitveg_mnv3s_pathA_gd_dendritic.pt\nTrain Epoch: 6 [0/3115 (0%)] Loss: 0.312213  Acc: 92.19%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 6 [1280/3115 (41%)] Loss: 0.218461  Acc: 93.15%\nTrain Epoch: 6 [2560/3115 (82%)] Loss: 0.221512  Acc: 93.33%\n\nValidation set: Average loss: 0.1999, Accuracy: 330/351 (94.02%)\n\nAdding validation score 94.01709402\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 5, last improved epoch 5, total epochs 5, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\n[INFO] Saved best model to ./outputs/fruitveg_mnv3s_pathA_gd_dendritic.pt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 7 [0/3115 (0%)] Loss: 0.201123  Acc: 95.31%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 7 [1280/3115 (41%)] Loss: 0.144195  Acc: 95.16%\nTrain Epoch: 7 [2560/3115 (82%)] Loss: 0.178040  Acc: 94.78%\n\nValidation set: Average loss: 0.1880, Accuracy: 333/351 (94.87%)\n\nAdding validation score 94.87179487\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 6, last improved epoch 6, total epochs 6, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\n[INFO] Saved best model to ./outputs/fruitveg_mnv3s_pathA_gd_dendritic.pt\nTrain Epoch: 8 [0/3115 (0%)] Loss: 0.099773  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 8 [1280/3115 (41%)] Loss: 0.140736  Acc: 96.21%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 8 [2560/3115 (82%)] Loss: 0.223040  Acc: 95.81%\n\nValidation set: Average loss: 0.1870, Accuracy: 333/351 (94.87%)\n\nAdding validation score 94.87179487\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 7, last improved epoch 6, total epochs 7, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 9 [0/3115 (0%)] Loss: 0.100778  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 9 [1280/3115 (41%)] Loss: 0.148093  Acc: 95.46%\nTrain Epoch: 9 [2560/3115 (82%)] Loss: 0.098732  Acc: 96.38%\n\nValidation set: Average loss: 0.1772, Accuracy: 333/351 (94.87%)\n\nAdding validation score 94.87179487\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 8, last improved epoch 6, total epochs 8, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\nTrain Epoch: 10 [0/3115 (0%)] Loss: 0.157925  Acc: 95.31%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 10 [1280/3115 (41%)] Loss: 0.096316  Acc: 96.95%\nTrain Epoch: 10 [2560/3115 (82%)] Loss: 0.258332  Acc: 96.65%\n\nValidation set: Average loss: 0.1762, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 9, last improved epoch 9, total epochs 9, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\n[INFO] Saved best model to ./outputs/fruitveg_mnv3s_pathA_gd_dendritic.pt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 11 [0/3115 (0%)] Loss: 0.134619  Acc: 95.31%\nTrain Epoch: 11 [1280/3115 (41%)] Loss: 0.142239  Acc: 97.32%\nTrain Epoch: 11 [2560/3115 (82%)] Loss: 0.102462  Acc: 97.33%\n\nValidation set: Average loss: 0.1723, Accuracy: 334/351 (95.16%)\n\nAdding validation score 95.15669516\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 10, last improved epoch 9, total epochs 10, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 12 [0/3115 (0%)] Loss: 0.121572  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 12 [1280/3115 (41%)] Loss: 0.075449  Acc: 97.25%\nTrain Epoch: 12 [2560/3115 (82%)] Loss: 0.132856  Acc: 96.99%\n\nValidation set: Average loss: 0.1679, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 11, last improved epoch 9, total epochs 11, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\nTrain Epoch: 13 [0/3115 (0%)] Loss: 0.116306  Acc: 96.88%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 13 [1280/3115 (41%)] Loss: 0.065509  Acc: 97.40%\nTrain Epoch: 13 [2560/3115 (82%)] Loss: 0.083965  Acc: 97.29%\n\nValidation set: Average loss: 0.1642, Accuracy: 336/351 (95.73%)\n\nAdding validation score 95.72649573\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 12, last improved epoch 12, total epochs 12, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\n[INFO] Saved best model to ./outputs/fruitveg_mnv3s_pathA_gd_dendritic.pt\nTrain Epoch: 14 [0/3115 (0%)] Loss: 0.082478  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 14 [1280/3115 (41%)] Loss: 0.115262  Acc: 97.47%\nTrain Epoch: 14 [2560/3115 (82%)] Loss: 0.096681  Acc: 97.33%\n\nValidation set: Average loss: 0.1611, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 13, last improved epoch 12, total epochs 13, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\nTrain Epoch: 15 [0/3115 (0%)] Loss: 0.146614  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 15 [1280/3115 (41%)] Loss: 0.164566  Acc: 96.88%\nTrain Epoch: 15 [2560/3115 (82%)] Loss: 0.070121  Acc: 97.52%\n\nValidation set: Average loss: 0.1614, Accuracy: 334/351 (95.16%)\n\nAdding validation score 95.15669516\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 14, last improved epoch 12, total epochs 14, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 16 [0/3115 (0%)] Loss: 0.121192  Acc: 96.88%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 16 [1280/3115 (41%)] Loss: 0.122575  Acc: 97.84%\nTrain Epoch: 16 [2560/3115 (82%)] Loss: 0.092525  Acc: 97.56%\n\nValidation set: Average loss: 0.1641, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 15, last improved epoch 12, total epochs 15, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 17 [0/3115 (0%)] Loss: 0.117996  Acc: 96.88%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 17 [1280/3115 (41%)] Loss: 0.070562  Acc: 97.77%\nTrain Epoch: 17 [2560/3115 (82%)] Loss: 0.071187  Acc: 97.94%\n\nValidation set: Average loss: 0.1648, Accuracy: 333/351 (94.87%)\n\nAdding validation score 94.87179487\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 16, last improved epoch 12, total epochs 16, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\nTrain Epoch: 18 [0/3115 (0%)] Loss: 0.093244  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 18 [1280/3115 (41%)] Loss: 0.083437  Acc: 97.77%\nTrain Epoch: 18 [2560/3115 (82%)] Loss: 0.145124  Acc: 97.90%\n\nValidation set: Average loss: 0.1636, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 17, last improved epoch 12, total epochs 17, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\nTrain Epoch: 19 [0/3115 (0%)] Loss: 0.079734  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 19 [1280/3115 (41%)] Loss: 0.132773  Acc: 97.47%\nTrain Epoch: 19 [2560/3115 (82%)] Loss: 0.111734  Acc: 97.83%\n\nValidation set: Average loss: 0.1626, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 18, last improved epoch 12, total epochs 18, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 20 [0/3115 (0%)] Loss: 0.057452  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 20 [1280/3115 (41%)] Loss: 0.157000  Acc: 97.99%\nTrain Epoch: 20 [2560/3115 (82%)] Loss: 0.091558  Acc: 98.25%\n\nValidation set: Average loss: 0.1622, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 19, last improved epoch 12, total epochs 19, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\nTrain Epoch: 21 [0/3115 (0%)] Loss: 0.111250  Acc: 96.88%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 21 [1280/3115 (41%)] Loss: 0.087565  Acc: 97.40%\nTrain Epoch: 21 [2560/3115 (82%)] Loss: 0.133295  Acc: 97.79%\n\nValidation set: Average loss: 0.1617, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 20, last improved epoch 12, total epochs 20, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\nTrain Epoch: 22 [0/3115 (0%)] Loss: 0.065611  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 22 [1280/3115 (41%)] Loss: 0.087201  Acc: 98.51%\nTrain Epoch: 22 [2560/3115 (82%)] Loss: 0.135882  Acc: 98.06%\n\nValidation set: Average loss: 0.1622, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 21, last improved epoch 12, total epochs 21, n: 10, num_cycles: 0\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=0 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 23 [0/3115 (0%)] Loss: 0.050918  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 23 [1280/3115 (41%)] Loss: 0.069701  Acc: 98.36%\nTrain Epoch: 23 [2560/3115 (82%)] Loss: 0.164107  Acc: 97.94%\n\nValidation set: Average loss: 0.1615, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 22, last improved epoch 12, total epochs 22, n: 10, num_cycles: 0\nReturning True - History and last improved is hit\nImporting best Model for switch to PA...\nSwitching back to N...\nResetting committed to initial rate to False\n[INFO] Model restructured → optimizer/scheduler reset.\n[INFO] PAI mode=n | dendrites_added=1 | restructured=1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 24 [0/3115 (0%)] Loss: 0.081328  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 24 [1280/3115 (41%)] Loss: 0.125480  Acc: 95.46%\nTrain Epoch: 24 [2560/3115 (82%)] Loss: 0.186127  Acc: 95.31%\n\nValidation set: Average loss: 0.2033, Accuracy: 332/351 (94.59%)\n\nAdding validation score 94.58689459\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 13, last improved epoch 13, total epochs 23, n: 10, num_cycles: 2\nReturning False - learning rate optimization in progress. Not committed yet. Comparing initial 0 to last max 11\n[INFO] PAI mode=n | dendrites_added=1 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 25 [0/3115 (0%)] Loss: 0.197237  Acc: 92.19%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 25 [1280/3115 (41%)] Loss: 0.118504  Acc: 97.10%\nTrain Epoch: 25 [2560/3115 (82%)] Loss: 0.143919  Acc: 97.26%\n\nValidation set: Average loss: 0.1716, Accuracy: 334/351 (95.16%)\n\nAdding validation score 95.15669516\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 14, last improved epoch 14, total epochs 24, n: 10, num_cycles: 2\nReturning False - learning rate optimization in progress. Not committed yet. Comparing initial 0 to last max 11\n[INFO] Model restructured → optimizer/scheduler reset.\n[INFO] PAI mode=n | dendrites_added=1 | restructured=1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 26 [0/3115 (0%)] Loss: 0.082418  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 26 [1280/3115 (41%)] Loss: 0.224155  Acc: 96.06%\nTrain Epoch: 26 [2560/3115 (82%)] Loss: 0.152565  Acc: 95.58%\n\nValidation set: Average loss: 0.2071, Accuracy: 329/351 (93.73%)\n\nAdding validation score 93.73219373\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 13, last improved epoch 13, total epochs 23, n: 10, num_cycles: 2\nReturning False - learning rate optimization in progress. Not committed yet. Comparing initial 1 to last max 11\n[INFO] Model restructured → optimizer/scheduler reset.\n[INFO] PAI mode=n | dendrites_added=1 | restructured=1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 27 [0/3115 (0%)] Loss: 0.107940  Acc: 95.31%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 27 [1280/3115 (41%)] Loss: 0.097119  Acc: 96.28%\nTrain Epoch: 27 [2560/3115 (82%)] Loss: 0.074625  Acc: 96.88%\n\nValidation set: Average loss: 0.1749, Accuracy: 334/351 (95.16%)\n\nAdding validation score 95.15669516\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 15, last improved epoch 15, total epochs 25, n: 10, num_cycles: 2\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=1 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 28 [0/3115 (0%)] Loss: 0.078285  Acc: 96.88%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 28 [1280/3115 (41%)] Loss: 0.040619  Acc: 97.99%\nTrain Epoch: 28 [2560/3115 (82%)] Loss: 0.037046  Acc: 98.13%\n\nValidation set: Average loss: 0.1685, Accuracy: 338/351 (96.30%)\n\nAdding validation score 96.29629630\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 16, last improved epoch 16, total epochs 26, n: 10, num_cycles: 2\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=1 | restructured=0\n[INFO] Saved best model to ./outputs/fruitveg_mnv3s_pathA_gd_dendritic.pt\nTrain Epoch: 29 [0/3115 (0%)] Loss: 0.044484  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 29 [1280/3115 (41%)] Loss: 0.100008  Acc: 98.66%\nTrain Epoch: 29 [2560/3115 (82%)] Loss: 0.092451  Acc: 98.40%\n\nValidation set: Average loss: 0.1558, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 17, last improved epoch 16, total epochs 27, n: 10, num_cycles: 2\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=1 | restructured=0\nTrain Epoch: 30 [0/3115 (0%)] Loss: 0.021450  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 30 [1280/3115 (41%)] Loss: 0.036759  Acc: 98.51%\nTrain Epoch: 30 [2560/3115 (82%)] Loss: 0.016019  Acc: 98.55%\n\nValidation set: Average loss: 0.1516, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 18, last improved epoch 16, total epochs 28, n: 10, num_cycles: 2\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=1 | restructured=0\nTrain Epoch: 31 [0/3115 (0%)] Loss: 0.023870  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 31 [1280/3115 (41%)] Loss: 0.018960  Acc: 98.74%\nTrain Epoch: 31 [2560/3115 (82%)] Loss: 0.024426  Acc: 98.93%\n\nValidation set: Average loss: 0.1487, Accuracy: 337/351 (96.01%)\n\nAdding validation score 96.01139601\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 19, last improved epoch 16, total epochs 29, n: 10, num_cycles: 2\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=1 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 32 [0/3115 (0%)] Loss: 0.023167  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 32 [1280/3115 (41%)] Loss: 0.039555  Acc: 99.03%\nTrain Epoch: 32 [2560/3115 (82%)] Loss: 0.013900  Acc: 99.01%\n\nValidation set: Average loss: 0.1452, Accuracy: 337/351 (96.01%)\n\nAdding validation score 96.01139601\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 20, last improved epoch 16, total epochs 30, n: 10, num_cycles: 2\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=1 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 33 [0/3115 (0%)] Loss: 0.044545  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 33 [1280/3115 (41%)] Loss: 0.044478  Acc: 98.96%\nTrain Epoch: 33 [2560/3115 (82%)] Loss: 0.024151  Acc: 98.93%\n\nValidation set: Average loss: 0.1430, Accuracy: 336/351 (95.73%)\n\nAdding validation score 95.72649573\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 21, last improved epoch 16, total epochs 31, n: 10, num_cycles: 2\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=1 | restructured=0\nTrain Epoch: 34 [0/3115 (0%)] Loss: 0.035084  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 34 [1280/3115 (41%)] Loss: 0.029487  Acc: 99.11%\nTrain Epoch: 34 [2560/3115 (82%)] Loss: 0.080811  Acc: 99.12%\n\nValidation set: Average loss: 0.1412, Accuracy: 336/351 (95.73%)\n\nAdding validation score 95.72649573\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 22, last improved epoch 16, total epochs 32, n: 10, num_cycles: 2\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=1 | restructured=0\nTrain Epoch: 35 [0/3115 (0%)] Loss: 0.016103  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 35 [1280/3115 (41%)] Loss: 0.009237  Acc: 98.96%\nTrain Epoch: 35 [2560/3115 (82%)] Loss: 0.010733  Acc: 99.12%\n\nValidation set: Average loss: 0.1407, Accuracy: 336/351 (95.73%)\n\nAdding validation score 95.72649573\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 23, last improved epoch 16, total epochs 33, n: 10, num_cycles: 2\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=1 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 36 [0/3115 (0%)] Loss: 0.036173  Acc: 98.44%\nTrain Epoch: 36 [1280/3115 (41%)] Loss: 0.009597  Acc: 99.03%\nTrain Epoch: 36 [2560/3115 (82%)] Loss: 0.011443  Acc: 99.01%\n\nValidation set: Average loss: 0.1500, Accuracy: 336/351 (95.73%)\n\nAdding validation score 95.72649573\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 24, last improved epoch 16, total epochs 34, n: 10, num_cycles: 2\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=1 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 37 [0/3115 (0%)] Loss: 0.022881  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 37 [1280/3115 (41%)] Loss: 0.017513  Acc: 99.33%\nTrain Epoch: 37 [2560/3115 (82%)] Loss: 0.036316  Acc: 99.16%\n\nValidation set: Average loss: 0.1486, Accuracy: 336/351 (95.73%)\n\nAdding validation score 95.72649573\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 25, last improved epoch 16, total epochs 35, n: 10, num_cycles: 2\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=1 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 38 [0/3115 (0%)] Loss: 0.061909  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 38 [1280/3115 (41%)] Loss: 0.027742  Acc: 99.40%\nTrain Epoch: 38 [2560/3115 (82%)] Loss: 0.041136  Acc: 99.31%\n\nValidation set: Average loss: 0.1475, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 26, last improved epoch 16, total epochs 36, n: 10, num_cycles: 2\nReturning True - History and last improved is hit\nImporting best Model for switch to PA...\nSwitching back to N...\nResetting committed to initial rate to False\n[INFO] Model restructured → optimizer/scheduler reset.\n[INFO] PAI mode=n | dendrites_added=2 | restructured=1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 39 [0/3115 (0%)] Loss: 0.067872  Acc: 96.88%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 39 [1280/3115 (41%)] Loss: 0.054576  Acc: 97.84%\nTrain Epoch: 39 [2560/3115 (82%)] Loss: 0.116586  Acc: 97.71%\n\nValidation set: Average loss: 0.1653, Accuracy: 333/351 (94.87%)\n\nAdding validation score 94.87179487\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 17, last improved epoch 17, total epochs 37, n: 10, num_cycles: 4\nReturning False - learning rate optimization in progress. Not committed yet. Comparing initial 0 to last max 3\n[INFO] PAI mode=n | dendrites_added=2 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 40 [0/3115 (0%)] Loss: 0.079053  Acc: 95.31%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 40 [1280/3115 (41%)] Loss: 0.046222  Acc: 98.29%\nTrain Epoch: 40 [2560/3115 (82%)] Loss: 0.102773  Acc: 98.17%\n\nValidation set: Average loss: 0.1896, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 18, last improved epoch 18, total epochs 38, n: 10, num_cycles: 4\nReturning False - learning rate optimization in progress. Not committed yet. Comparing initial 0 to last max 3\n[INFO] Model restructured → optimizer/scheduler reset.\n[INFO] PAI mode=n | dendrites_added=2 | restructured=1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 41 [0/3115 (0%)] Loss: 0.052645  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 41 [1280/3115 (41%)] Loss: 0.071637  Acc: 97.10%\nTrain Epoch: 41 [2560/3115 (82%)] Loss: 0.055564  Acc: 96.95%\n\nValidation set: Average loss: 0.1719, Accuracy: 334/351 (95.16%)\n\nAdding validation score 95.15669516\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 17, last improved epoch 17, total epochs 37, n: 10, num_cycles: 4\nReturning False - learning rate optimization in progress. Not committed yet. Comparing initial 1 to last max 3\n[INFO] Model restructured → optimizer/scheduler reset.\n[INFO] PAI mode=n | dendrites_added=2 | restructured=1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 42 [0/3115 (0%)] Loss: 0.061967  Acc: 96.88%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 42 [1280/3115 (41%)] Loss: 0.096556  Acc: 97.92%\nTrain Epoch: 42 [2560/3115 (82%)] Loss: 0.043952  Acc: 97.75%\n\nValidation set: Average loss: 0.1679, Accuracy: 333/351 (94.87%)\n\nAdding validation score 94.87179487\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 19, last improved epoch 19, total epochs 39, n: 10, num_cycles: 4\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=2 | restructured=0\nTrain Epoch: 43 [0/3115 (0%)] Loss: 0.026075  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 43 [1280/3115 (41%)] Loss: 0.063988  Acc: 98.36%\nTrain Epoch: 43 [2560/3115 (82%)] Loss: 0.071563  Acc: 98.55%\n\nValidation set: Average loss: 0.1528, Accuracy: 337/351 (96.01%)\n\nAdding validation score 96.01139601\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 20, last improved epoch 20, total epochs 40, n: 10, num_cycles: 4\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=2 | restructured=0\nTrain Epoch: 44 [0/3115 (0%)] Loss: 0.006888  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 44 [1280/3115 (41%)] Loss: 0.010620  Acc: 99.11%\nTrain Epoch: 44 [2560/3115 (82%)] Loss: 0.014327  Acc: 99.01%\n\nValidation set: Average loss: 0.1632, Accuracy: 333/351 (94.87%)\n\nAdding validation score 94.87179487\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 21, last improved epoch 20, total epochs 41, n: 10, num_cycles: 4\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=2 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 45 [0/3115 (0%)] Loss: 0.023888  Acc: 100.00%\nTrain Epoch: 45 [1280/3115 (41%)] Loss: 0.016204  Acc: 98.74%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 45 [2560/3115 (82%)] Loss: 0.005580  Acc: 98.97%\n\nValidation set: Average loss: 0.1593, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 22, last improved epoch 20, total epochs 42, n: 10, num_cycles: 4\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=2 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 46 [0/3115 (0%)] Loss: 0.027329  Acc: 98.44%\nTrain Epoch: 46 [1280/3115 (41%)] Loss: 0.010732  Acc: 99.11%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 46 [2560/3115 (82%)] Loss: 0.021458  Acc: 99.01%\n\nValidation set: Average loss: 0.1562, Accuracy: 334/351 (95.16%)\n\nAdding validation score 95.15669516\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 23, last improved epoch 20, total epochs 43, n: 10, num_cycles: 4\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=2 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 47 [0/3115 (0%)] Loss: 0.012736  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 47 [1280/3115 (41%)] Loss: 0.010373  Acc: 99.11%\nTrain Epoch: 47 [2560/3115 (82%)] Loss: 0.026544  Acc: 99.12%\n\nValidation set: Average loss: 0.1437, Accuracy: 336/351 (95.73%)\n\nAdding validation score 95.72649573\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 24, last improved epoch 20, total epochs 44, n: 10, num_cycles: 4\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=2 | restructured=0\nTrain Epoch: 48 [0/3115 (0%)] Loss: 0.057889  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 48 [1280/3115 (41%)] Loss: 0.043228  Acc: 99.03%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 48 [2560/3115 (82%)] Loss: 0.044504  Acc: 98.97%\n\nValidation set: Average loss: 0.1442, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 25, last improved epoch 20, total epochs 45, n: 10, num_cycles: 4\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=2 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 49 [0/3115 (0%)] Loss: 0.034430  Acc: 98.44%\nTrain Epoch: 49 [1280/3115 (41%)] Loss: 0.021266  Acc: 98.96%\nTrain Epoch: 49 [2560/3115 (82%)] Loss: 0.009744  Acc: 99.20%\n\nValidation set: Average loss: 0.1430, Accuracy: 338/351 (96.30%)\n\nAdding validation score 96.29629630\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 26, last improved epoch 26, total epochs 46, n: 10, num_cycles: 4\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=2 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 50 [0/3115 (0%)] Loss: 0.034629  Acc: 98.44%\nTrain Epoch: 50 [1280/3115 (41%)] Loss: 0.003469  Acc: 99.11%\nTrain Epoch: 50 [2560/3115 (82%)] Loss: 0.011117  Acc: 99.28%\n\nValidation set: Average loss: 0.1440, Accuracy: 336/351 (95.73%)\n\nAdding validation score 95.72649573\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 27, last improved epoch 26, total epochs 47, n: 10, num_cycles: 4\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=2 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 51 [0/3115 (0%)] Loss: 0.009140  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 51 [1280/3115 (41%)] Loss: 0.010394  Acc: 99.03%\nTrain Epoch: 51 [2560/3115 (82%)] Loss: 0.022873  Acc: 99.09%\n\nValidation set: Average loss: 0.1297, Accuracy: 338/351 (96.30%)\n\nAdding validation score 96.29629630\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 28, last improved epoch 26, total epochs 48, n: 10, num_cycles: 4\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=2 | restructured=0\nTrain Epoch: 52 [0/3115 (0%)] Loss: 0.019296  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 52 [1280/3115 (41%)] Loss: 0.031576  Acc: 99.11%\nTrain Epoch: 52 [2560/3115 (82%)] Loss: 0.020945  Acc: 99.28%\n\nValidation set: Average loss: 0.1341, Accuracy: 340/351 (96.87%)\n\nAdding validation score 96.86609687\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 29, last improved epoch 29, total epochs 49, n: 10, num_cycles: 4\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=2 | restructured=0\n[INFO] Saved best model to ./outputs/fruitveg_mnv3s_pathA_gd_dendritic.pt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 53 [0/3115 (0%)] Loss: 0.003690  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 53 [1280/3115 (41%)] Loss: 0.013985  Acc: 99.48%\nTrain Epoch: 53 [2560/3115 (82%)] Loss: 0.013641  Acc: 99.39%\n\nValidation set: Average loss: 0.1392, Accuracy: 337/351 (96.01%)\n\nAdding validation score 96.01139601\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 30, last improved epoch 29, total epochs 50, n: 10, num_cycles: 4\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=2 | restructured=0\nTrain Epoch: 54 [0/3115 (0%)] Loss: 0.010791  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 54 [1280/3115 (41%)] Loss: 0.015166  Acc: 99.40%\nTrain Epoch: 54 [2560/3115 (82%)] Loss: 0.009285  Acc: 99.24%\n\nValidation set: Average loss: 0.1405, Accuracy: 337/351 (96.01%)\n\nAdding validation score 96.01139601\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 31, last improved epoch 29, total epochs 51, n: 10, num_cycles: 4\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=2 | restructured=0\nTrain Epoch: 55 [0/3115 (0%)] Loss: 0.017794  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 55 [1280/3115 (41%)] Loss: 0.012634  Acc: 99.18%\nTrain Epoch: 55 [2560/3115 (82%)] Loss: 0.010902  Acc: 99.16%\n\nValidation set: Average loss: 0.1377, Accuracy: 338/351 (96.30%)\n\nAdding validation score 96.29629630\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 32, last improved epoch 29, total epochs 52, n: 10, num_cycles: 4\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=2 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 56 [0/3115 (0%)] Loss: 0.036414  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 56 [1280/3115 (41%)] Loss: 0.008824  Acc: 99.26%\nTrain Epoch: 56 [2560/3115 (82%)] Loss: 0.039008  Acc: 99.16%\n\nValidation set: Average loss: 0.1357, Accuracy: 338/351 (96.30%)\n\nAdding validation score 96.29629630\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 33, last improved epoch 29, total epochs 53, n: 10, num_cycles: 4\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=2 | restructured=0\nTrain Epoch: 57 [0/3115 (0%)] Loss: 0.010414  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 57 [1280/3115 (41%)] Loss: 0.045378  Acc: 99.40%\nTrain Epoch: 57 [2560/3115 (82%)] Loss: 0.007354  Acc: 99.43%\n\nValidation set: Average loss: 0.1363, Accuracy: 339/351 (96.58%)\n\nAdding validation score 96.58119658\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 34, last improved epoch 29, total epochs 54, n: 10, num_cycles: 4\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=2 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 58 [0/3115 (0%)] Loss: 0.058133  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 58 [1280/3115 (41%)] Loss: 0.015725  Acc: 99.18%\nTrain Epoch: 58 [2560/3115 (82%)] Loss: 0.016834  Acc: 99.39%\n\nValidation set: Average loss: 0.1370, Accuracy: 339/351 (96.58%)\n\nAdding validation score 96.58119658\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 35, last improved epoch 29, total epochs 55, n: 10, num_cycles: 4\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=2 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 59 [0/3115 (0%)] Loss: 0.003279  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 59 [1280/3115 (41%)] Loss: 0.004238  Acc: 99.03%\nTrain Epoch: 59 [2560/3115 (82%)] Loss: 0.006940  Acc: 99.05%\n\nValidation set: Average loss: 0.1369, Accuracy: 338/351 (96.30%)\n\nAdding validation score 96.29629630\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 36, last improved epoch 29, total epochs 56, n: 10, num_cycles: 4\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=2 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 60 [0/3115 (0%)] Loss: 0.047202  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 60 [1280/3115 (41%)] Loss: 0.012932  Acc: 99.33%\nTrain Epoch: 60 [2560/3115 (82%)] Loss: 0.061136  Acc: 99.35%\n\nValidation set: Average loss: 0.1380, Accuracy: 338/351 (96.30%)\n\nAdding validation score 96.29629630\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 37, last improved epoch 29, total epochs 57, n: 10, num_cycles: 4\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=2 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 61 [0/3115 (0%)] Loss: 0.011148  Acc: 100.00%\nTrain Epoch: 61 [1280/3115 (41%)] Loss: 0.006105  Acc: 99.55%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 61 [2560/3115 (82%)] Loss: 0.004693  Acc: 99.47%\n\nValidation set: Average loss: 0.1377, Accuracy: 339/351 (96.58%)\n\nAdding validation score 96.58119658\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 38, last improved epoch 29, total epochs 58, n: 10, num_cycles: 4\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=2 | restructured=0\nTrain Epoch: 62 [0/3115 (0%)] Loss: 0.016230  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 62 [1280/3115 (41%)] Loss: 0.023506  Acc: 98.96%\nTrain Epoch: 62 [2560/3115 (82%)] Loss: 0.016859  Acc: 99.24%\n\nValidation set: Average loss: 0.1375, Accuracy: 338/351 (96.30%)\n\nAdding validation score 96.29629630\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 39, last improved epoch 29, total epochs 59, n: 10, num_cycles: 4\nReturning True - History and last improved is hit\nImporting best Model for switch to PA...\nSwitching back to N...\nResetting committed to initial rate to False\n[INFO] Model restructured → optimizer/scheduler reset.\n[INFO] PAI mode=n | dendrites_added=3 | restructured=1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 63 [0/3115 (0%)] Loss: 0.045194  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 63 [1280/3115 (41%)] Loss: 0.060684  Acc: 98.44%\nTrain Epoch: 63 [2560/3115 (82%)] Loss: 0.056253  Acc: 98.02%\n\nValidation set: Average loss: 0.1762, Accuracy: 336/351 (95.73%)\n\nAdding validation score 95.72649573\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 30, last improved epoch 30, total epochs 60, n: 10, num_cycles: 6\nReturning False - learning rate optimization in progress. Not committed yet. Comparing initial 0 to last max 12\n[INFO] PAI mode=n | dendrites_added=3 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 64 [0/3115 (0%)] Loss: 0.035894  Acc: 98.44%\nTrain Epoch: 64 [1280/3115 (41%)] Loss: 0.014605  Acc: 98.59%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 64 [2560/3115 (82%)] Loss: 0.008210  Acc: 98.59%\n\nValidation set: Average loss: 0.1622, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 31, last improved epoch 30, total epochs 61, n: 10, num_cycles: 6\nReturning False - learning rate optimization in progress. Not committed yet. Comparing initial 0 to last max 12\n[INFO] Model restructured → optimizer/scheduler reset.\n[INFO] PAI mode=n | dendrites_added=3 | restructured=1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 65 [0/3115 (0%)] Loss: 0.004005  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 65 [1280/3115 (41%)] Loss: 0.049774  Acc: 98.74%\nTrain Epoch: 65 [2560/3115 (82%)] Loss: 0.092458  Acc: 98.09%\n\nValidation set: Average loss: 0.1626, Accuracy: 337/351 (96.01%)\n\nAdding validation score 96.01139601\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 30, last improved epoch 30, total epochs 60, n: 10, num_cycles: 6\nReturning False - learning rate optimization in progress. Not committed yet. Comparing initial 1 to last max 12\n[INFO] PAI mode=n | dendrites_added=3 | restructured=0\nTrain Epoch: 66 [0/3115 (0%)] Loss: 0.040582  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 66 [1280/3115 (41%)] Loss: 0.057767  Acc: 98.74%\nTrain Epoch: 66 [2560/3115 (82%)] Loss: 0.020000  Acc: 98.70%\n\nValidation set: Average loss: 0.1578, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 31, last improved epoch 30, total epochs 61, n: 10, num_cycles: 6\nReturning False - learning rate optimization in progress. Not committed yet. Comparing initial 1 to last max 12\n[INFO] Model restructured → optimizer/scheduler reset.\n[INFO] PAI mode=n | dendrites_added=3 | restructured=1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 67 [0/3115 (0%)] Loss: 0.012158  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 67 [1280/3115 (41%)] Loss: 0.003474  Acc: 99.26%\nTrain Epoch: 67 [2560/3115 (82%)] Loss: 0.018892  Acc: 98.74%\n\nValidation set: Average loss: 0.1337, Accuracy: 336/351 (95.73%)\n\nAdding validation score 95.72649573\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 30, last improved epoch 30, total epochs 60, n: 10, num_cycles: 6\nReturning False - learning rate optimization in progress. Not committed yet. Comparing initial 2 to last max 12\n[INFO] Model restructured → optimizer/scheduler reset.\n[INFO] PAI mode=n | dendrites_added=3 | restructured=1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 68 [0/3115 (0%)] Loss: 0.010152  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 68 [1280/3115 (41%)] Loss: 0.043300  Acc: 98.51%\nTrain Epoch: 68 [2560/3115 (82%)] Loss: 0.067776  Acc: 98.44%\n\nValidation set: Average loss: 0.1411, Accuracy: 340/351 (96.87%)\n\nAdding validation score 96.86609687\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 32, last improved epoch 32, total epochs 62, n: 10, num_cycles: 6\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=3 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 69 [0/3115 (0%)] Loss: 0.015898  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 69 [1280/3115 (41%)] Loss: 0.009529  Acc: 98.59%\nTrain Epoch: 69 [2560/3115 (82%)] Loss: 0.028273  Acc: 98.74%\n\nValidation set: Average loss: 0.1468, Accuracy: 338/351 (96.30%)\n\nAdding validation score 96.29629630\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 33, last improved epoch 32, total epochs 63, n: 10, num_cycles: 6\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=3 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 70 [0/3115 (0%)] Loss: 0.033498  Acc: 98.44%\nTrain Epoch: 70 [1280/3115 (41%)] Loss: 0.021608  Acc: 99.18%\nTrain Epoch: 70 [2560/3115 (82%)] Loss: 0.030445  Acc: 98.70%\n\nValidation set: Average loss: 0.1250, Accuracy: 339/351 (96.58%)\n\nAdding validation score 96.58119658\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 34, last improved epoch 32, total epochs 64, n: 10, num_cycles: 6\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=3 | restructured=0\nTrain Epoch: 71 [0/3115 (0%)] Loss: 0.018194  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 71 [1280/3115 (41%)] Loss: 0.036345  Acc: 99.03%\nTrain Epoch: 71 [2560/3115 (82%)] Loss: 0.051833  Acc: 99.20%\n\nValidation set: Average loss: 0.1299, Accuracy: 338/351 (96.30%)\n\nAdding validation score 96.29629630\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 35, last improved epoch 32, total epochs 65, n: 10, num_cycles: 6\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=3 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 72 [0/3115 (0%)] Loss: 0.014950  Acc: 100.00%\nTrain Epoch: 72 [1280/3115 (41%)] Loss: 0.014241  Acc: 99.40%\nTrain Epoch: 72 [2560/3115 (82%)] Loss: 0.053036  Acc: 99.09%\n\nValidation set: Average loss: 0.1288, Accuracy: 339/351 (96.58%)\n\nAdding validation score 96.58119658\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 36, last improved epoch 32, total epochs 66, n: 10, num_cycles: 6\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=3 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 73 [0/3115 (0%)] Loss: 0.012403  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 73 [1280/3115 (41%)] Loss: 0.020832  Acc: 99.18%\nTrain Epoch: 73 [2560/3115 (82%)] Loss: 0.007052  Acc: 99.20%\n\nValidation set: Average loss: 0.1364, Accuracy: 339/351 (96.58%)\n\nAdding validation score 96.58119658\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 37, last improved epoch 32, total epochs 67, n: 10, num_cycles: 6\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=3 | restructured=0\nTrain Epoch: 74 [0/3115 (0%)] Loss: 0.014786  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 74 [1280/3115 (41%)] Loss: 0.007546  Acc: 99.55%\nTrain Epoch: 74 [2560/3115 (82%)] Loss: 0.036207  Acc: 99.24%\n\nValidation set: Average loss: 0.1328, Accuracy: 340/351 (96.87%)\n\nAdding validation score 96.86609687\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 38, last improved epoch 32, total epochs 68, n: 10, num_cycles: 6\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=3 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 75 [0/3115 (0%)] Loss: 0.023012  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 75 [1280/3115 (41%)] Loss: 0.018353  Acc: 99.26%\nTrain Epoch: 75 [2560/3115 (82%)] Loss: 0.003491  Acc: 99.24%\n\nValidation set: Average loss: 0.1272, Accuracy: 340/351 (96.87%)\n\nAdding validation score 96.86609687\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 39, last improved epoch 32, total epochs 69, n: 10, num_cycles: 6\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=3 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 76 [0/3115 (0%)] Loss: 0.031415  Acc: 98.44%\nTrain Epoch: 76 [1280/3115 (41%)] Loss: 0.007360  Acc: 99.48%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 76 [2560/3115 (82%)] Loss: 0.068913  Acc: 99.35%\n\nValidation set: Average loss: 0.1280, Accuracy: 340/351 (96.87%)\n\nAdding validation score 96.86609687\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 40, last improved epoch 32, total epochs 70, n: 10, num_cycles: 6\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=3 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 77 [0/3115 (0%)] Loss: 0.001118  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 77 [1280/3115 (41%)] Loss: 0.003193  Acc: 99.11%\nTrain Epoch: 77 [2560/3115 (82%)] Loss: 0.001566  Acc: 99.20%\n\nValidation set: Average loss: 0.1314, Accuracy: 341/351 (97.15%)\n\nAdding validation score 97.15099715\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 41, last improved epoch 41, total epochs 71, n: 10, num_cycles: 6\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=3 | restructured=0\n[INFO] Saved best model to ./outputs/fruitveg_mnv3s_pathA_gd_dendritic.pt\nTrain Epoch: 78 [0/3115 (0%)] Loss: 0.007074  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 78 [1280/3115 (41%)] Loss: 0.027534  Acc: 98.88%\nTrain Epoch: 78 [2560/3115 (82%)] Loss: 0.004350  Acc: 99.20%\n\nValidation set: Average loss: 0.1338, Accuracy: 339/351 (96.58%)\n\nAdding validation score 96.58119658\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 42, last improved epoch 41, total epochs 72, n: 10, num_cycles: 6\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=3 | restructured=0\nTrain Epoch: 79 [0/3115 (0%)] Loss: 0.005926  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 79 [1280/3115 (41%)] Loss: 0.030496  Acc: 99.48%\nTrain Epoch: 79 [2560/3115 (82%)] Loss: 0.035307  Acc: 99.31%\n\nValidation set: Average loss: 0.1335, Accuracy: 341/351 (97.15%)\n\nAdding validation score 97.15099715\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 43, last improved epoch 41, total epochs 73, n: 10, num_cycles: 6\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=3 | restructured=0\nTrain Epoch: 80 [0/3115 (0%)] Loss: 0.046122  Acc: 96.88%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 80 [1280/3115 (41%)] Loss: 0.030578  Acc: 99.40%\nTrain Epoch: 80 [2560/3115 (82%)] Loss: 0.025569  Acc: 99.35%\n\nValidation set: Average loss: 0.1345, Accuracy: 339/351 (96.58%)\n\nAdding validation score 96.58119658\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 44, last improved epoch 41, total epochs 74, n: 10, num_cycles: 6\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=3 | restructured=0\nTrain Epoch: 81 [0/3115 (0%)] Loss: 0.044613  Acc: 96.88%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 81 [1280/3115 (41%)] Loss: 0.009338  Acc: 99.26%\nTrain Epoch: 81 [2560/3115 (82%)] Loss: 0.050987  Acc: 99.20%\n\nValidation set: Average loss: 0.1323, Accuracy: 340/351 (96.87%)\n\nAdding validation score 96.86609687\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 45, last improved epoch 41, total epochs 75, n: 10, num_cycles: 6\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=3 | restructured=0\nTrain Epoch: 82 [0/3115 (0%)] Loss: 0.005063  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 82 [1280/3115 (41%)] Loss: 0.003785  Acc: 99.26%\nTrain Epoch: 82 [2560/3115 (82%)] Loss: 0.008371  Acc: 99.16%\n\nValidation set: Average loss: 0.1331, Accuracy: 340/351 (96.87%)\n\nAdding validation score 96.86609687\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 46, last improved epoch 41, total epochs 76, n: 10, num_cycles: 6\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=3 | restructured=0\nTrain Epoch: 83 [0/3115 (0%)] Loss: 0.011868  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 83 [1280/3115 (41%)] Loss: 0.024966  Acc: 99.33%\nTrain Epoch: 83 [2560/3115 (82%)] Loss: 0.001747  Acc: 99.31%\n\nValidation set: Average loss: 0.1343, Accuracy: 340/351 (96.87%)\n\nAdding validation score 96.86609687\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 47, last improved epoch 41, total epochs 77, n: 10, num_cycles: 6\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=3 | restructured=0\nTrain Epoch: 84 [0/3115 (0%)] Loss: 0.015596  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 84 [1280/3115 (41%)] Loss: 0.017577  Acc: 99.03%\nTrain Epoch: 84 [2560/3115 (82%)] Loss: 0.020934  Acc: 99.12%\n\nValidation set: Average loss: 0.1339, Accuracy: 340/351 (96.87%)\n\nAdding validation score 96.86609687\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 48, last improved epoch 41, total epochs 78, n: 10, num_cycles: 6\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=3 | restructured=0\nTrain Epoch: 85 [0/3115 (0%)] Loss: 0.010442  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 85 [1280/3115 (41%)] Loss: 0.007727  Acc: 99.26%\nTrain Epoch: 85 [2560/3115 (82%)] Loss: 0.010003  Acc: 99.16%\n\nValidation set: Average loss: 0.1348, Accuracy: 340/351 (96.87%)\n\nAdding validation score 96.86609687\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 49, last improved epoch 41, total epochs 79, n: 10, num_cycles: 6\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=3 | restructured=0\nTrain Epoch: 86 [0/3115 (0%)] Loss: 0.012370  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 86 [1280/3115 (41%)] Loss: 0.063036  Acc: 99.26%\nTrain Epoch: 86 [2560/3115 (82%)] Loss: 0.001499  Acc: 99.39%\n\nValidation set: Average loss: 0.1347, Accuracy: 340/351 (96.87%)\n\nAdding validation score 96.86609687\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 50, last improved epoch 41, total epochs 80, n: 10, num_cycles: 6\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=3 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 87 [0/3115 (0%)] Loss: 0.055207  Acc: 96.88%\nTrain Epoch: 87 [1280/3115 (41%)] Loss: 0.045176  Acc: 99.26%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 87 [2560/3115 (82%)] Loss: 0.008999  Acc: 99.24%\n\nValidation set: Average loss: 0.1349, Accuracy: 339/351 (96.58%)\n\nAdding validation score 96.58119658\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 51, last improved epoch 41, total epochs 81, n: 10, num_cycles: 6\nReturning True - History and last improved is hit\nImporting best Model for switch to PA...\nSwitching back to N...\nResetting committed to initial rate to False\n[INFO] Model restructured → optimizer/scheduler reset.\n[INFO] PAI mode=n | dendrites_added=4 | restructured=1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 88 [0/3115 (0%)] Loss: 0.000923  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 88 [1280/3115 (41%)] Loss: 0.047934  Acc: 98.88%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 88 [2560/3115 (82%)] Loss: 0.037658  Acc: 98.67%\n\nValidation set: Average loss: 0.1995, Accuracy: 332/351 (94.59%)\n\nAdding validation score 94.58689459\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 42, last improved epoch 42, total epochs 82, n: 10, num_cycles: 8\nReturning False - learning rate optimization in progress. Not committed yet. Comparing initial 0 to last max 12\n[INFO] PAI mode=n | dendrites_added=4 | restructured=0\nTrain Epoch: 89 [0/3115 (0%)] Loss: 0.044637  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 89 [1280/3115 (41%)] Loss: 0.025860  Acc: 99.03%\nTrain Epoch: 89 [2560/3115 (82%)] Loss: 0.025392  Acc: 98.67%\n\nValidation set: Average loss: 0.2055, Accuracy: 332/351 (94.59%)\n\nAdding validation score 94.58689459\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 43, last improved epoch 42, total epochs 83, n: 10, num_cycles: 8\nReturning False - learning rate optimization in progress. Not committed yet. Comparing initial 0 to last max 12\n[INFO] Model restructured → optimizer/scheduler reset.\n[INFO] PAI mode=n | dendrites_added=4 | restructured=1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 90 [0/3115 (0%)] Loss: 0.000705  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 90 [1280/3115 (41%)] Loss: 0.106965  Acc: 98.74%\nTrain Epoch: 90 [2560/3115 (82%)] Loss: 0.010033  Acc: 98.55%\n\nValidation set: Average loss: 0.1926, Accuracy: 331/351 (94.30%)\n\nAdding validation score 94.30199430\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 42, last improved epoch 42, total epochs 82, n: 10, num_cycles: 8\nReturning False - learning rate optimization in progress. Not committed yet. Comparing initial 1 to last max 12\n[INFO] Model restructured → optimizer/scheduler reset.\n[INFO] PAI mode=n | dendrites_added=4 | restructured=1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 91 [0/3115 (0%)] Loss: 0.041053  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 91 [1280/3115 (41%)] Loss: 0.006510  Acc: 98.36%\nTrain Epoch: 91 [2560/3115 (82%)] Loss: 0.003554  Acc: 98.78%\n\nValidation set: Average loss: 0.1540, Accuracy: 336/351 (95.73%)\n\nAdding validation score 95.72649573\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 44, last improved epoch 44, total epochs 84, n: 10, num_cycles: 8\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=4 | restructured=0\nTrain Epoch: 92 [0/3115 (0%)] Loss: 0.004289  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 92 [1280/3115 (41%)] Loss: 0.010328  Acc: 99.26%\nTrain Epoch: 92 [2560/3115 (82%)] Loss: 0.042977  Acc: 99.12%\n\nValidation set: Average loss: 0.1390, Accuracy: 337/351 (96.01%)\n\nAdding validation score 96.01139601\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 45, last improved epoch 45, total epochs 85, n: 10, num_cycles: 8\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=4 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 93 [0/3115 (0%)] Loss: 0.010738  Acc: 100.00%\nTrain Epoch: 93 [1280/3115 (41%)] Loss: 0.032901  Acc: 98.96%\nTrain Epoch: 93 [2560/3115 (82%)] Loss: 0.022148  Acc: 98.89%\n\nValidation set: Average loss: 0.1318, Accuracy: 337/351 (96.01%)\n\nAdding validation score 96.01139601\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 46, last improved epoch 45, total epochs 86, n: 10, num_cycles: 8\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=4 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 94 [0/3115 (0%)] Loss: 0.026163  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 94 [1280/3115 (41%)] Loss: 0.010982  Acc: 99.11%\nTrain Epoch: 94 [2560/3115 (82%)] Loss: 0.003321  Acc: 98.89%\n\nValidation set: Average loss: 0.1277, Accuracy: 339/351 (96.58%)\n\nAdding validation score 96.58119658\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 47, last improved epoch 47, total epochs 87, n: 10, num_cycles: 8\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=4 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 95 [0/3115 (0%)] Loss: 0.012583  Acc: 100.00%\nTrain Epoch: 95 [1280/3115 (41%)] Loss: 0.001946  Acc: 99.33%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 95 [2560/3115 (82%)] Loss: 0.003877  Acc: 99.16%\n\nValidation set: Average loss: 0.1210, Accuracy: 342/351 (97.44%)\n\nAdding validation score 97.43589744\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 48, last improved epoch 48, total epochs 88, n: 10, num_cycles: 8\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=4 | restructured=0\n[INFO] Saved best model to ./outputs/fruitveg_mnv3s_pathA_gd_dendritic.pt\nTrain Epoch: 96 [0/3115 (0%)] Loss: 0.018823  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 96 [1280/3115 (41%)] Loss: 0.007383  Acc: 99.26%\nTrain Epoch: 96 [2560/3115 (82%)] Loss: 0.019231  Acc: 98.97%\n\nValidation set: Average loss: 0.1246, Accuracy: 340/351 (96.87%)\n\nAdding validation score 96.86609687\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 49, last improved epoch 48, total epochs 89, n: 10, num_cycles: 8\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=4 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 97 [0/3115 (0%)] Loss: 0.008507  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 97 [1280/3115 (41%)] Loss: 0.023595  Acc: 99.18%\nTrain Epoch: 97 [2560/3115 (82%)] Loss: 0.050131  Acc: 99.24%\n\nValidation set: Average loss: 0.1246, Accuracy: 341/351 (97.15%)\n\nAdding validation score 97.15099715\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 50, last improved epoch 48, total epochs 90, n: 10, num_cycles: 8\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=4 | restructured=0\nTrain Epoch: 98 [0/3115 (0%)] Loss: 0.055204  Acc: 96.88%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 98 [1280/3115 (41%)] Loss: 0.009671  Acc: 99.40%\nTrain Epoch: 98 [2560/3115 (82%)] Loss: 0.008333  Acc: 99.28%\n\nValidation set: Average loss: 0.1325, Accuracy: 340/351 (96.87%)\n\nAdding validation score 96.86609687\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 51, last improved epoch 48, total epochs 91, n: 10, num_cycles: 8\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=4 | restructured=0\nTrain Epoch: 99 [0/3115 (0%)] Loss: 0.002475  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 99 [1280/3115 (41%)] Loss: 0.009891  Acc: 99.63%\nTrain Epoch: 99 [2560/3115 (82%)] Loss: 0.004793  Acc: 99.39%\n\nValidation set: Average loss: 0.1377, Accuracy: 340/351 (96.87%)\n\nAdding validation score 96.86609687\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 52, last improved epoch 48, total epochs 92, n: 10, num_cycles: 8\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=4 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 100 [0/3115 (0%)] Loss: 0.004986  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 100 [1280/3115 (41%)] Loss: 0.011163  Acc: 99.48%\nTrain Epoch: 100 [2560/3115 (82%)] Loss: 0.025468  Acc: 99.47%\n\nValidation set: Average loss: 0.1366, Accuracy: 340/351 (96.87%)\n\nAdding validation score 96.86609687\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 53, last improved epoch 48, total epochs 93, n: 10, num_cycles: 8\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=4 | restructured=0\nTrain Epoch: 101 [0/3115 (0%)] Loss: 0.009038  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 101 [1280/3115 (41%)] Loss: 0.003442  Acc: 99.55%\nTrain Epoch: 101 [2560/3115 (82%)] Loss: 0.013614  Acc: 99.39%\n\nValidation set: Average loss: 0.1355, Accuracy: 341/351 (97.15%)\n\nAdding validation score 97.15099715\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 54, last improved epoch 48, total epochs 94, n: 10, num_cycles: 8\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=4 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 102 [0/3115 (0%)] Loss: 0.002114  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 102 [1280/3115 (41%)] Loss: 0.012294  Acc: 99.48%\nTrain Epoch: 102 [2560/3115 (82%)] Loss: 0.011445  Acc: 99.35%\n\nValidation set: Average loss: 0.1376, Accuracy: 341/351 (97.15%)\n\nAdding validation score 97.15099715\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 55, last improved epoch 48, total epochs 95, n: 10, num_cycles: 8\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=4 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 103 [0/3115 (0%)] Loss: 0.012388  Acc: 100.00%\nTrain Epoch: 103 [1280/3115 (41%)] Loss: 0.000708  Acc: 99.40%\nTrain Epoch: 103 [2560/3115 (82%)] Loss: 0.015131  Acc: 99.35%\n\nValidation set: Average loss: 0.1365, Accuracy: 341/351 (97.15%)\n\nAdding validation score 97.15099715\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 56, last improved epoch 48, total epochs 96, n: 10, num_cycles: 8\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=4 | restructured=0\nTrain Epoch: 104 [0/3115 (0%)] Loss: 0.000886  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 104 [1280/3115 (41%)] Loss: 0.001265  Acc: 98.88%\nTrain Epoch: 104 [2560/3115 (82%)] Loss: 0.009177  Acc: 99.05%\n\nValidation set: Average loss: 0.1320, Accuracy: 340/351 (96.87%)\n\nAdding validation score 96.86609687\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 57, last improved epoch 48, total epochs 97, n: 10, num_cycles: 8\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=4 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 105 [0/3115 (0%)] Loss: 0.000948  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 105 [1280/3115 (41%)] Loss: 0.012367  Acc: 99.78%\nTrain Epoch: 105 [2560/3115 (82%)] Loss: 0.057821  Acc: 99.47%\n\nValidation set: Average loss: 0.1323, Accuracy: 340/351 (96.87%)\n\nAdding validation score 96.86609687\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 58, last improved epoch 48, total epochs 98, n: 10, num_cycles: 8\nReturning True - History and last improved is hit\nImporting best Model for switch to PA...\nSwitching back to N...\nResetting committed to initial rate to False\n[INFO] Model restructured → optimizer/scheduler reset.\n[INFO] PAI mode=n | dendrites_added=5 | restructured=1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 106 [0/3115 (0%)] Loss: 0.002730  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 106 [1280/3115 (41%)] Loss: 0.049928  Acc: 99.03%\nTrain Epoch: 106 [2560/3115 (82%)] Loss: 0.004540  Acc: 98.63%\n\nValidation set: Average loss: 0.1903, Accuracy: 333/351 (94.87%)\n\nAdding validation score 94.87179487\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 49, last improved epoch 49, total epochs 99, n: 10, num_cycles: 10\nReturning False - learning rate optimization in progress. Not committed yet. Comparing initial 0 to last max 6\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\nTrain Epoch: 107 [0/3115 (0%)] Loss: 0.010759  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 107 [1280/3115 (41%)] Loss: 0.016475  Acc: 98.96%\nTrain Epoch: 107 [2560/3115 (82%)] Loss: 0.036712  Acc: 98.59%\n\nValidation set: Average loss: 0.1918, Accuracy: 331/351 (94.30%)\n\nAdding validation score 94.30199430\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 50, last improved epoch 49, total epochs 100, n: 10, num_cycles: 10\nReturning False - learning rate optimization in progress. Not committed yet. Comparing initial 0 to last max 6\n[INFO] Model restructured → optimizer/scheduler reset.\n[INFO] PAI mode=n | dendrites_added=5 | restructured=1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 108 [0/3115 (0%)] Loss: 0.003775  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 108 [1280/3115 (41%)] Loss: 0.054218  Acc: 98.66%\nTrain Epoch: 108 [2560/3115 (82%)] Loss: 0.020388  Acc: 98.70%\n\nValidation set: Average loss: 0.2065, Accuracy: 332/351 (94.59%)\n\nAdding validation score 94.58689459\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 49, last improved epoch 49, total epochs 99, n: 10, num_cycles: 10\nReturning False - learning rate optimization in progress. Not committed yet. Comparing initial 1 to last max 6\n[INFO] Model restructured → optimizer/scheduler reset.\n[INFO] PAI mode=n | dendrites_added=5 | restructured=1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 109 [0/3115 (0%)] Loss: 0.010565  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 109 [1280/3115 (41%)] Loss: 0.050426  Acc: 99.03%\nTrain Epoch: 109 [2560/3115 (82%)] Loss: 0.029701  Acc: 98.74%\n\nValidation set: Average loss: 0.2081, Accuracy: 334/351 (95.16%)\n\nAdding validation score 95.15669516\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 51, last improved epoch 51, total epochs 101, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\nTrain Epoch: 110 [0/3115 (0%)] Loss: 0.010168  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 110 [1280/3115 (41%)] Loss: 0.053431  Acc: 98.51%\nTrain Epoch: 110 [2560/3115 (82%)] Loss: 0.108841  Acc: 98.67%\n\nValidation set: Average loss: 0.1730, Accuracy: 337/351 (96.01%)\n\nAdding validation score 96.01139601\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 52, last improved epoch 52, total epochs 102, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 111 [0/3115 (0%)] Loss: 0.002783  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 111 [1280/3115 (41%)] Loss: 0.041266  Acc: 98.81%\nTrain Epoch: 111 [2560/3115 (82%)] Loss: 0.014795  Acc: 99.01%\n\nValidation set: Average loss: 0.1713, Accuracy: 336/351 (95.73%)\n\nAdding validation score 95.72649573\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 53, last improved epoch 52, total epochs 103, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\nTrain Epoch: 112 [0/3115 (0%)] Loss: 0.041664  Acc: 96.88%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 112 [1280/3115 (41%)] Loss: 0.016827  Acc: 99.11%\nTrain Epoch: 112 [2560/3115 (82%)] Loss: 0.000674  Acc: 99.01%\n\nValidation set: Average loss: 0.1491, Accuracy: 338/351 (96.30%)\n\nAdding validation score 96.29629630\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 54, last improved epoch 54, total epochs 104, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\nTrain Epoch: 113 [0/3115 (0%)] Loss: 0.009088  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 113 [1280/3115 (41%)] Loss: 0.023280  Acc: 99.55%\nTrain Epoch: 113 [2560/3115 (82%)] Loss: 0.011041  Acc: 99.47%\n\nValidation set: Average loss: 0.1471, Accuracy: 338/351 (96.30%)\n\nAdding validation score 96.29629630\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 55, last improved epoch 54, total epochs 105, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\nTrain Epoch: 114 [0/3115 (0%)] Loss: 0.018072  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 114 [1280/3115 (41%)] Loss: 0.012407  Acc: 99.26%\nTrain Epoch: 114 [2560/3115 (82%)] Loss: 0.039080  Acc: 99.16%\n\nValidation set: Average loss: 0.1446, Accuracy: 337/351 (96.01%)\n\nAdding validation score 96.01139601\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 56, last improved epoch 54, total epochs 106, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\nTrain Epoch: 115 [0/3115 (0%)] Loss: 0.017009  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 115 [1280/3115 (41%)] Loss: 0.021015  Acc: 99.18%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 115 [2560/3115 (82%)] Loss: 0.001970  Acc: 99.24%\n\nValidation set: Average loss: 0.1422, Accuracy: 340/351 (96.87%)\n\nAdding validation score 96.86609687\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 57, last improved epoch 57, total epochs 107, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\nTrain Epoch: 116 [0/3115 (0%)] Loss: 0.019713  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 116 [1280/3115 (41%)] Loss: 0.020906  Acc: 99.33%\nTrain Epoch: 116 [2560/3115 (82%)] Loss: 0.010190  Acc: 99.20%\n\nValidation set: Average loss: 0.1410, Accuracy: 339/351 (96.58%)\n\nAdding validation score 96.58119658\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 58, last improved epoch 57, total epochs 108, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\nTrain Epoch: 117 [0/3115 (0%)] Loss: 0.018431  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 117 [1280/3115 (41%)] Loss: 0.004909  Acc: 99.48%\nTrain Epoch: 117 [2560/3115 (82%)] Loss: 0.050139  Acc: 99.47%\n\nValidation set: Average loss: 0.1453, Accuracy: 338/351 (96.30%)\n\nAdding validation score 96.29629630\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 59, last improved epoch 57, total epochs 109, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\nTrain Epoch: 118 [0/3115 (0%)] Loss: 0.021308  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 118 [1280/3115 (41%)] Loss: 0.002872  Acc: 99.33%\nTrain Epoch: 118 [2560/3115 (82%)] Loss: 0.023972  Acc: 99.28%\n\nValidation set: Average loss: 0.1469, Accuracy: 338/351 (96.30%)\n\nAdding validation score 96.29629630\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 60, last improved epoch 57, total epochs 110, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 119 [0/3115 (0%)] Loss: 0.004614  Acc: 100.00%\nTrain Epoch: 119 [1280/3115 (41%)] Loss: 0.014072  Acc: 99.33%\nTrain Epoch: 119 [2560/3115 (82%)] Loss: 0.001228  Acc: 99.24%\n\nValidation set: Average loss: 0.1488, Accuracy: 339/351 (96.58%)\n\nAdding validation score 96.58119658\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 61, last improved epoch 57, total epochs 111, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 120 [0/3115 (0%)] Loss: 0.021560  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 120 [1280/3115 (41%)] Loss: 0.005180  Acc: 99.03%\nTrain Epoch: 120 [2560/3115 (82%)] Loss: 0.007362  Acc: 99.28%\n\nValidation set: Average loss: 0.1466, Accuracy: 339/351 (96.58%)\n\nAdding validation score 96.58119658\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 62, last improved epoch 57, total epochs 112, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\nTrain Epoch: 121 [0/3115 (0%)] Loss: 0.035742  Acc: 96.88%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 121 [1280/3115 (41%)] Loss: 0.018773  Acc: 99.48%\nTrain Epoch: 121 [2560/3115 (82%)] Loss: 0.038713  Acc: 99.43%\n\nValidation set: Average loss: 0.1483, Accuracy: 338/351 (96.30%)\n\nAdding validation score 96.29629630\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 63, last improved epoch 57, total epochs 113, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 122 [0/3115 (0%)] Loss: 0.000867  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 122 [1280/3115 (41%)] Loss: 0.000394  Acc: 99.03%\nTrain Epoch: 122 [2560/3115 (82%)] Loss: 0.021251  Acc: 99.20%\n\nValidation set: Average loss: 0.1474, Accuracy: 338/351 (96.30%)\n\nAdding validation score 96.29629630\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 64, last improved epoch 57, total epochs 114, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 123 [0/3115 (0%)] Loss: 0.030725  Acc: 96.88%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 123 [1280/3115 (41%)] Loss: 0.013897  Acc: 99.18%\nTrain Epoch: 123 [2560/3115 (82%)] Loss: 0.000255  Acc: 99.20%\n\nValidation set: Average loss: 0.1468, Accuracy: 340/351 (96.87%)\n\nAdding validation score 96.86609687\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 65, last improved epoch 57, total epochs 115, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\nTrain Epoch: 124 [0/3115 (0%)] Loss: 0.000182  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 124 [1280/3115 (41%)] Loss: 0.011808  Acc: 99.40%\nTrain Epoch: 124 [2560/3115 (82%)] Loss: 0.037114  Acc: 99.39%\n\nValidation set: Average loss: 0.1458, Accuracy: 340/351 (96.87%)\n\nAdding validation score 96.86609687\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 66, last improved epoch 57, total epochs 116, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 125 [0/3115 (0%)] Loss: 0.000609  Acc: 100.00%\nTrain Epoch: 125 [1280/3115 (41%)] Loss: 0.002810  Acc: 99.55%\nTrain Epoch: 125 [2560/3115 (82%)] Loss: 0.001807  Acc: 99.35%\n\nValidation set: Average loss: 0.1450, Accuracy: 340/351 (96.87%)\n\nAdding validation score 96.86609687\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 67, last improved epoch 57, total epochs 117, n: 10, num_cycles: 10\nReturning True - History and last improved is hit\nDendrites did not improve but current tries 1 is less than max tries 2 so loading last switch and trying new Dendrites.\nImporting best Model for switch to PA...\nSwitching back to N...\nResetting committed to initial rate to False\n[INFO] Model restructured → optimizer/scheduler reset.\n[INFO] PAI mode=n | dendrites_added=5 | restructured=1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 126 [0/3115 (0%)] Loss: 0.001681  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 126 [1280/3115 (41%)] Loss: 0.009459  Acc: 98.96%\nTrain Epoch: 126 [2560/3115 (82%)] Loss: 0.218685  Acc: 98.48%\n\nValidation set: Average loss: 0.1847, Accuracy: 336/351 (95.73%)\n\nAdding validation score 95.72649573\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 49, last improved epoch 49, total epochs 118, n: 10, num_cycles: 10\nReturning False - learning rate optimization in progress. Not committed yet. Comparing initial 0 to last max 6\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 127 [0/3115 (0%)] Loss: 0.030510  Acc: 98.44%\nTrain Epoch: 127 [1280/3115 (41%)] Loss: 0.017327  Acc: 98.59%\nTrain Epoch: 127 [2560/3115 (82%)] Loss: 0.019932  Acc: 98.40%\n\nValidation set: Average loss: 0.1960, Accuracy: 333/351 (94.87%)\n\nAdding validation score 94.87179487\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 50, last improved epoch 49, total epochs 119, n: 10, num_cycles: 10\nReturning False - learning rate optimization in progress. Not committed yet. Comparing initial 0 to last max 6\n[INFO] Model restructured → optimizer/scheduler reset.\n[INFO] PAI mode=n | dendrites_added=5 | restructured=1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 128 [0/3115 (0%)] Loss: 0.002754  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 128 [1280/3115 (41%)] Loss: 0.016209  Acc: 99.11%\nTrain Epoch: 128 [2560/3115 (82%)] Loss: 0.133656  Acc: 99.01%\n\nValidation set: Average loss: 0.1515, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 49, last improved epoch 49, total epochs 118, n: 10, num_cycles: 10\nReturning False - learning rate optimization in progress. Not committed yet. Comparing initial 1 to last max 6\n[INFO] Model restructured → optimizer/scheduler reset.\n[INFO] PAI mode=n | dendrites_added=5 | restructured=1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 129 [0/3115 (0%)] Loss: 0.018846  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 129 [1280/3115 (41%)] Loss: 0.020642  Acc: 98.66%\nTrain Epoch: 129 [2560/3115 (82%)] Loss: 0.013849  Acc: 98.89%\n\nValidation set: Average loss: 0.2216, Accuracy: 334/351 (95.16%)\n\nAdding validation score 95.15669516\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 51, last improved epoch 51, total epochs 120, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 130 [0/3115 (0%)] Loss: 0.029137  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 130 [1280/3115 (41%)] Loss: 0.002962  Acc: 99.26%\nTrain Epoch: 130 [2560/3115 (82%)] Loss: 0.038143  Acc: 98.82%\n\nValidation set: Average loss: 0.1971, Accuracy: 332/351 (94.59%)\n\nAdding validation score 94.58689459\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 52, last improved epoch 51, total epochs 121, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 131 [0/3115 (0%)] Loss: 0.017356  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 131 [1280/3115 (41%)] Loss: 0.010311  Acc: 99.18%\nTrain Epoch: 131 [2560/3115 (82%)] Loss: 0.011196  Acc: 99.16%\n\nValidation set: Average loss: 0.2003, Accuracy: 334/351 (95.16%)\n\nAdding validation score 95.15669516\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 53, last improved epoch 51, total epochs 122, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\nTrain Epoch: 132 [0/3115 (0%)] Loss: 0.008647  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 132 [1280/3115 (41%)] Loss: 0.003106  Acc: 99.03%\nTrain Epoch: 132 [2560/3115 (82%)] Loss: 0.061055  Acc: 99.09%\n\nValidation set: Average loss: 0.1527, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 54, last improved epoch 51, total epochs 123, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 133 [0/3115 (0%)] Loss: 0.013186  Acc: 100.00%\nTrain Epoch: 133 [1280/3115 (41%)] Loss: 0.058045  Acc: 99.26%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 133 [2560/3115 (82%)] Loss: 0.012129  Acc: 99.01%\n\nValidation set: Average loss: 0.1615, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 55, last improved epoch 51, total epochs 124, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 134 [0/3115 (0%)] Loss: 0.015724  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 134 [1280/3115 (41%)] Loss: 0.007118  Acc: 99.33%\nTrain Epoch: 134 [2560/3115 (82%)] Loss: 0.012273  Acc: 99.05%\n\nValidation set: Average loss: 0.1566, Accuracy: 337/351 (96.01%)\n\nAdding validation score 96.01139601\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 56, last improved epoch 56, total epochs 125, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\nTrain Epoch: 135 [0/3115 (0%)] Loss: 0.028689  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 135 [1280/3115 (41%)] Loss: 0.035901  Acc: 99.03%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 135 [2560/3115 (82%)] Loss: 0.001223  Acc: 99.20%\n\nValidation set: Average loss: 0.1550, Accuracy: 338/351 (96.30%)\n\nAdding validation score 96.29629630\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 57, last improved epoch 57, total epochs 126, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 136 [0/3115 (0%)] Loss: 0.019167  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 136 [1280/3115 (41%)] Loss: 0.001036  Acc: 99.33%\nTrain Epoch: 136 [2560/3115 (82%)] Loss: 0.004500  Acc: 99.16%\n\nValidation set: Average loss: 0.1514, Accuracy: 336/351 (95.73%)\n\nAdding validation score 95.72649573\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 58, last improved epoch 57, total epochs 127, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\nTrain Epoch: 137 [0/3115 (0%)] Loss: 0.020453  Acc: 98.44%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 137 [1280/3115 (41%)] Loss: 0.000748  Acc: 99.40%\nTrain Epoch: 137 [2560/3115 (82%)] Loss: 0.019106  Acc: 99.28%\n\nValidation set: Average loss: 0.1513, Accuracy: 337/351 (96.01%)\n\nAdding validation score 96.01139601\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 59, last improved epoch 57, total epochs 128, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 138 [0/3115 (0%)] Loss: 0.054775  Acc: 96.88%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 138 [1280/3115 (41%)] Loss: 0.005213  Acc: 99.26%\nTrain Epoch: 138 [2560/3115 (82%)] Loss: 0.020341  Acc: 99.16%\n\nValidation set: Average loss: 0.1479, Accuracy: 338/351 (96.30%)\n\nAdding validation score 96.29629630\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 60, last improved epoch 57, total epochs 129, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 139 [0/3115 (0%)] Loss: 0.028950  Acc: 98.44%\nTrain Epoch: 139 [1280/3115 (41%)] Loss: 0.012227  Acc: 99.11%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 139 [2560/3115 (82%)] Loss: 0.011793  Acc: 99.09%\n\nValidation set: Average loss: 0.1496, Accuracy: 338/351 (96.30%)\n\nAdding validation score 96.29629630\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 61, last improved epoch 57, total epochs 130, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 140 [0/3115 (0%)] Loss: 0.001897  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 140 [1280/3115 (41%)] Loss: 0.026202  Acc: 99.48%\nTrain Epoch: 140 [2560/3115 (82%)] Loss: 0.000915  Acc: 99.43%\n\nValidation set: Average loss: 0.1502, Accuracy: 336/351 (95.73%)\n\nAdding validation score 95.72649573\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 62, last improved epoch 57, total epochs 131, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 141 [0/3115 (0%)] Loss: 0.004297  Acc: 100.00%\nTrain Epoch: 141 [1280/3115 (41%)] Loss: 0.000728  Acc: 99.33%\nTrain Epoch: 141 [2560/3115 (82%)] Loss: 0.001191  Acc: 99.31%\n\nValidation set: Average loss: 0.1469, Accuracy: 335/351 (95.44%)\n\nAdding validation score 95.44159544\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 63, last improved epoch 57, total epochs 132, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 142 [0/3115 (0%)] Loss: 0.001840  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 142 [1280/3115 (41%)] Loss: 0.008060  Acc: 99.48%\nTrain Epoch: 142 [2560/3115 (82%)] Loss: 0.000562  Acc: 99.20%\n\nValidation set: Average loss: 0.1435, Accuracy: 337/351 (96.01%)\n\nAdding validation score 96.01139601\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 64, last improved epoch 57, total epochs 133, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 143 [0/3115 (0%)] Loss: 0.002967  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 143 [1280/3115 (41%)] Loss: 0.001147  Acc: 99.48%\nTrain Epoch: 143 [2560/3115 (82%)] Loss: 0.010646  Acc: 99.50%\n\nValidation set: Average loss: 0.1446, Accuracy: 338/351 (96.30%)\n\nAdding validation score 96.29629630\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 65, last improved epoch 57, total epochs 134, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\nTrain Epoch: 144 [0/3115 (0%)] Loss: 0.000860  Acc: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 144 [1280/3115 (41%)] Loss: 0.001625  Acc: 99.11%\nTrain Epoch: 144 [2560/3115 (82%)] Loss: 0.012424  Acc: 98.97%\n\nValidation set: Average loss: 0.1456, Accuracy: 337/351 (96.01%)\n\nAdding validation score 96.01139601\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 66, last improved epoch 57, total epochs 135, n: 10, num_cycles: 10\nReturning False - no triggers to switch have been hit\n[INFO] PAI mode=n | dendrites_added=5 | restructured=0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 145 [0/3115 (0%)] Loss: 0.004826  Acc: 100.00%\nTrain Epoch: 145 [1280/3115 (41%)] Loss: 0.003070  Acc: 99.40%\nTrain Epoch: 145 [2560/3115 (82%)] Loss: 0.000655  Acc: 99.31%\n\nValidation set: Average loss: 0.1463, Accuracy: 338/351 (96.30%)\n\nAdding validation score 96.29629630\nChecking PAI switch with mode n, switch mode DOING_HISTORY, epoch 67, last improved epoch 57, total epochs 136, n: 10, num_cycles: 10\nReturning True - History and last improved is hit\nDendrites did not improve system and 2 > 2 so returning training_complete.\nYou should now exit your training loop and best_model will be your final model for inference\nFor improved results, try perforated backpropagation next time!\nbefore graphs\nafter graphs\nafter save\n[INFO] PAI mode=n | dendrites_added=4 | restructured=True\n[INFO] PerforatedAI reports training complete. Stopping early.\n\nTest set: Average loss: 0.1184, Accuracy: 350/359 (97.49%)\n\n[DONE] Metrics saved to: ./outputs/pathA_gd_dendritic_metrics.json\n[DONE] Best Val Acc: 97.44% | Test Acc: 97.49%\n[DONE] Time: 199.3 minutes\n\n[IMPORTANT] For judging, include the PerforatedAI graph image:\n  -> ./PAI/PAI.png  (usually ./PAI/PAI.png)\n\n","output_type":"stream"}],"execution_count":7}]}